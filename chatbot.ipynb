{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f59b11e96d346bb91acd65ea97747cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a547a48b529d4837806b955d20838710",
              "IPY_MODEL_7325c62c51214bc39f121ce57091f082",
              "IPY_MODEL_740da8b3089d4326aedb172d7e559e0e"
            ],
            "layout": "IPY_MODEL_9e31bf219fec46d0b8a39dd35ec83eb5"
          }
        },
        "a547a48b529d4837806b955d20838710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74cf862300914af7ba1ecf6f7843441e",
            "placeholder": "​",
            "style": "IPY_MODEL_1c2d4cd36e95405b89ae9d847bfa4a48",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7325c62c51214bc39f121ce57091f082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8734987489b94c10a47fbd3c6cb31f73",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29cfc95fe8ca40d89d9f7ddb8ae8d649",
            "value": 28
          }
        },
        "740da8b3089d4326aedb172d7e559e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4129021b17a402dae5b607037064441",
            "placeholder": "​",
            "style": "IPY_MODEL_160165212ff24755a417caefbfc9b94a",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.21kB/s]"
          }
        },
        "9e31bf219fec46d0b8a39dd35ec83eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74cf862300914af7ba1ecf6f7843441e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c2d4cd36e95405b89ae9d847bfa4a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8734987489b94c10a47fbd3c6cb31f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cfc95fe8ca40d89d9f7ddb8ae8d649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4129021b17a402dae5b607037064441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160165212ff24755a417caefbfc9b94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35ae40f7768e403f93b350c652980cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b17fb5ff5e3649ac8dace4e1b5d77eee",
              "IPY_MODEL_55fd18e5de1c4a6a8346cb3fe9edc57a",
              "IPY_MODEL_98e4cb9419b24c2abdf6fb0742bcbc08"
            ],
            "layout": "IPY_MODEL_707dd63b63644de18ed53f414c9e6c4e"
          }
        },
        "b17fb5ff5e3649ac8dace4e1b5d77eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cde2f0fe92a423ba26c8fe8e48efb5c",
            "placeholder": "​",
            "style": "IPY_MODEL_2c29e711988c4e9fbac389bf11c68de9",
            "value": "config.json: 100%"
          }
        },
        "55fd18e5de1c4a6a8346cb3fe9edc57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e268445352a94bd2a874ec5ed63c7e25",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b995a62a2994dc6addb056fb55ceb0f",
            "value": 483
          }
        },
        "98e4cb9419b24c2abdf6fb0742bcbc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32229aec92c54abebfd7b61f78afa917",
            "placeholder": "​",
            "style": "IPY_MODEL_1ceea8bb68db499ca6d8ac347f6f094d",
            "value": " 483/483 [00:00&lt;00:00, 6.38kB/s]"
          }
        },
        "707dd63b63644de18ed53f414c9e6c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cde2f0fe92a423ba26c8fe8e48efb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c29e711988c4e9fbac389bf11c68de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e268445352a94bd2a874ec5ed63c7e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b995a62a2994dc6addb056fb55ceb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32229aec92c54abebfd7b61f78afa917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ceea8bb68db499ca6d8ac347f6f094d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbd4977a7ee45649ce98aa969c10888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a620c693335448fab807fbf9a12aa717",
              "IPY_MODEL_0308e7a96dd94739ae47f64ecf73f940",
              "IPY_MODEL_e05e73e3f1ca456b8a66d88671220a82"
            ],
            "layout": "IPY_MODEL_f65480219ee5489494ad93db84c26df7"
          }
        },
        "a620c693335448fab807fbf9a12aa717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d8a125ad3f4a248820e324b8057baf",
            "placeholder": "​",
            "style": "IPY_MODEL_17879a85342d4f60aba7fbd2ccdefe33",
            "value": "vocab.txt: 100%"
          }
        },
        "0308e7a96dd94739ae47f64ecf73f940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13bd9bcb4e0a4ab1adc59b113a38556e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93784ffcacf24d68902f3be138602caa",
            "value": 231508
          }
        },
        "e05e73e3f1ca456b8a66d88671220a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565b2e8549884701b2a543924a484df2",
            "placeholder": "​",
            "style": "IPY_MODEL_38471f64d57d4e0a9d2294c3b343ecd1",
            "value": " 232k/232k [00:00&lt;00:00, 3.70MB/s]"
          }
        },
        "f65480219ee5489494ad93db84c26df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d8a125ad3f4a248820e324b8057baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17879a85342d4f60aba7fbd2ccdefe33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13bd9bcb4e0a4ab1adc59b113a38556e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93784ffcacf24d68902f3be138602caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "565b2e8549884701b2a543924a484df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38471f64d57d4e0a9d2294c3b343ecd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a4d49e4b7cf436b8c4f054cc1d01ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6d4e640f04f4327aa68c85a9bc1921e",
              "IPY_MODEL_bd2b23bd9078403d827bb40c73f42adc",
              "IPY_MODEL_93a874c6078b4c7fa97c0a941b25e185"
            ],
            "layout": "IPY_MODEL_b3302ef5eaf447ceba5f88924ee0577b"
          }
        },
        "b6d4e640f04f4327aa68c85a9bc1921e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87a7aad7b454da28e345ec31717c0f3",
            "placeholder": "​",
            "style": "IPY_MODEL_399dae459d8c4270a909733300e2077b",
            "value": "tokenizer.json: 100%"
          }
        },
        "bd2b23bd9078403d827bb40c73f42adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7851e89e1c9d49f8898a918495c6cfaf",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_020916b186a545feb55f120ad8e4c8f6",
            "value": 466062
          }
        },
        "93a874c6078b4c7fa97c0a941b25e185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4034657f238c47f8a7fb89db84552df3",
            "placeholder": "​",
            "style": "IPY_MODEL_e2825ac428f4494886393482b5645ca6",
            "value": " 466k/466k [00:00&lt;00:00, 6.95MB/s]"
          }
        },
        "b3302ef5eaf447ceba5f88924ee0577b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87a7aad7b454da28e345ec31717c0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399dae459d8c4270a909733300e2077b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7851e89e1c9d49f8898a918495c6cfaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020916b186a545feb55f120ad8e4c8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4034657f238c47f8a7fb89db84552df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2825ac428f4494886393482b5645ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfEkqT2YVqHX",
        "outputId": "257f117b-0925-4aaf-fcf0-ef2230990fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\n",
        "!unzip -n WikiQACorpus.zip\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD0Qm7s9WQj9",
        "outputId": "67d1018b-79d6-44a1-9ea8-c0a57807976f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-15 12:06:52--  https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.62.142.15, 2600:1407:3c00:e9b::317f, 2600:1407:3c00:ea3::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.62.142.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7094233 (6.8M) [application/octet-stream]\n",
            "Saving to: ‘WikiQACorpus.zip’\n",
            "\n",
            "WikiQACorpus.zip    100%[===================>]   6.76M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-02-15 12:06:53 (60.8 MB/s) - ‘WikiQACorpus.zip’ saved [7094233/7094233]\n",
            "\n",
            "Archive:  WikiQACorpus.zip\n",
            "   creating: WikiQACorpus/emnlp-table/\n",
            "  inflating: WikiQACorpus/emnlp-table/WikiQA.CNN.dev.rank  \n",
            "  inflating: WikiQACorpus/emnlp-table/WikiQA.CNN.test.rank  \n",
            "  inflating: WikiQACorpus/emnlp-table/WikiQA.CNN-Cnt.dev.rank  \n",
            "  inflating: WikiQACorpus/emnlp-table/WikiQA.CNN-Cnt.test.rank  \n",
            "  inflating: WikiQACorpus/eval.py    \n",
            "  inflating: WikiQACorpus/Guidelines_Phase1.pdf  \n",
            "  inflating: WikiQACorpus/Guidelines_Phase2.pdf  \n",
            "  inflating: WikiQACorpus/WikiQA.tsv  \n",
            "  inflating: WikiQACorpus/WikiQA-dev.ref  \n",
            "  inflating: WikiQACorpus/WikiQA-dev.tsv  \n",
            "  inflating: WikiQACorpus/WikiQA-dev.txt  \n",
            "  inflating: WikiQACorpus/WikiQA-dev-filtered.ref  \n",
            "  inflating: WikiQACorpus/WikiQASent.pos.ans.tsv  \n",
            "  inflating: WikiQACorpus/WikiQA-test.ref  \n",
            "  inflating: WikiQACorpus/WikiQA-test.tsv  \n",
            "  inflating: WikiQACorpus/WikiQA-test.txt  \n",
            "  inflating: WikiQACorpus/WikiQA-test-filtered.ref  \n",
            "  inflating: WikiQACorpus/WikiQA-train.ref  \n",
            "  inflating: WikiQACorpus/WikiQA-train.tsv  \n",
            "  inflating: WikiQACorpus/WikiQA-train.txt  \n",
            "  inflating: WikiQACorpus/LICENSE.pdf  \n",
            "  inflating: WikiQACorpus/README.txt  \n",
            "sample_data  WikiQACorpus  WikiQACorpus.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "sVmfiix8WSuy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls WikiQACorpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4BAd1ZLWX4j",
        "outputId": "7cd4ba59-bdad-4579-e496-58bf9c5805b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emnlp-table\t       README.txt\t\tWikiQASent.pos.ans.tsv\t  WikiQA-train.ref\n",
            "eval.py\t\t       WikiQA-dev-filtered.ref\tWikiQA-test-filtered.ref  WikiQA-train.tsv\n",
            "Guidelines_Phase1.pdf  WikiQA-dev.ref\t\tWikiQA-test.ref\t\t  WikiQA-train.txt\n",
            "Guidelines_Phase2.pdf  WikiQA-dev.tsv\t\tWikiQA-test.tsv\t\t  WikiQA.tsv\n",
            "LICENSE.pdf\t       WikiQA-dev.txt\t\tWikiQA-test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def get_dataset(ds_path: str):\n",
        "  ds = pd.read_csv(ds_path, sep='\\t', names=['question', 'answer', 'label'])\n",
        "  ds = ds[ds['label'] == 1]\n",
        "  return ds\n",
        "\n",
        "train_ds = get_dataset(\"./WikiQACorpus/WikiQA-train.txt\")\n",
        "val_ds = get_dataset(\"./WikiQACorpus/WikiQA-dev.txt\")\n",
        "test_ds = get_dataset(\"./WikiQACorpus/WikiQA-test.txt\")"
      ],
      "metadata": {
        "id": "Sk635S48de94"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_yT94upBhKDp",
        "outputId": "18ffb3e4-c160-43d0-d549-e29d663e55df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         question  \\\n",
              "3                  how are glacier caves formed ?   \n",
              "75              how much is 1 tablespoon of water   \n",
              "83              how much is 1 tablespoon of water   \n",
              "84              how much is 1 tablespoon of water   \n",
              "98     how much are the harry potter movies worth   \n",
              "...                                           ...   \n",
              "20305               What is an economic feature ?   \n",
              "20320         what is the average american income   \n",
              "20338             When was Apple Computer founded   \n",
              "20348               what is section eight housing   \n",
              "20349               what is section eight housing   \n",
              "\n",
              "                                                  answer  label  \n",
              "3      A glacier cave is a cave formed within the ice...      1  \n",
              "75       This tablespoon has a capacity of about 15 mL .      1  \n",
              "83     In the USA one tablespoon ( measurement unit )...      1  \n",
              "84     In Australia one tablespoon ( measurement unit...      1  \n",
              "98     The series also originated much tie-in merchan...      1  \n",
              "...                                                  ...    ...  \n",
              "20305  At the turn of the 21st century , the expandin...      1  \n",
              "20320  U.S. median household income fell from $ 51,14...      1  \n",
              "20338  The company was founded on April 1 , 1976 , an...      1  \n",
              "20348  Section 8 of the Housing Act of 1937 ( ) , oft...      1  \n",
              "20349  It operates through several programs , the lar...      1  \n",
              "\n",
              "[1040 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2eb0437e-e1f1-4204-8077-cdec9fd01e29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how are glacier caves formed ?</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>how much is 1 tablespoon of water</td>\n",
              "      <td>This tablespoon has a capacity of about 15 mL .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>how much is 1 tablespoon of water</td>\n",
              "      <td>In the USA one tablespoon ( measurement unit )...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>how much is 1 tablespoon of water</td>\n",
              "      <td>In Australia one tablespoon ( measurement unit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>how much are the harry potter movies worth</td>\n",
              "      <td>The series also originated much tie-in merchan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20305</th>\n",
              "      <td>What is an economic feature ?</td>\n",
              "      <td>At the turn of the 21st century , the expandin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20320</th>\n",
              "      <td>what is the average american income</td>\n",
              "      <td>U.S. median household income fell from $ 51,14...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20338</th>\n",
              "      <td>When was Apple Computer founded</td>\n",
              "      <td>The company was founded on April 1 , 1976 , an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20348</th>\n",
              "      <td>what is section eight housing</td>\n",
              "      <td>Section 8 of the Housing Act of 1937 ( ) , oft...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20349</th>\n",
              "      <td>what is section eight housing</td>\n",
              "      <td>It operates through several programs , the lar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1040 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2eb0437e-e1f1-4204-8077-cdec9fd01e29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2eb0437e-e1f1-4204-8077-cdec9fd01e29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2eb0437e-e1f1-4204-8077-cdec9fd01e29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33bc311c-ea6e-4288-8c8f-d57627af0ab6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33bc311c-ea6e-4288-8c8f-d57627af0ab6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33bc311c-ea6e-4288-8c8f-d57627af0ab6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0f526e0c-6c6e-420b-a738-94bcc26f4e5d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_ds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0f526e0c-6c6e-420b-a738-94bcc26f4e5d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_ds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_ds",
              "summary": "{\n  \"name\": \"train_ds\",\n  \"rows\": 1040,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"WHAT IS NON BINDING ?\",\n          \"what are spoilers for\",\n          \"what is amoxicillin for ?\"\n        ],\n        \"num_unique_values\": 873,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"It was released in 1990 as the third single from Aerosmith 's critically and commercially successful 1989 album Pump .\",\n          \"New Orleans ( or , locally or ; ) is a major United States port and the largest city and metropolitan area in the state of Louisiana .\",\n          \"Jehovah 's Witnesses ' beliefs are based on their interpretations of the Bible and they prefer to use their own translation , the New World Translation of the Holy Scriptures .\"\n        ],\n        \"num_unique_values\": 1029,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"samples\": [\n          1\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "\n",
        "MAX_SEQ_LENGTH = 50\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, max_words=10000, max_sequence_length=100):\n",
        "        self.tokenizer = Tokenizer(num_words=max_words, oov_token='<UNK>')\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.tokenizer.fit_on_texts(['<PAD>', '<START>', '<STOP>', '<UNK>'])\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        text = text.lower()\n",
        "        # Remove punctuation\n",
        "        text = re.sub(r'[`.,*#{}\\[\\]\\-=_():;!?\\'\"]', '', text)\n",
        "        return text\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        # Update tokenizer with provided texts\n",
        "        preprocessed_texts = [self.preprocess_text(text) for text in texts]\n",
        "        self.tokenizer.fit_on_texts(preprocessed_texts)\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        preprocessed_texts = [self.preprocess_text(text) for text in texts]\n",
        "        sequences = self.tokenizer.texts_to_sequences(preprocessed_texts)\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = self.tokenizer.sequences_to_texts(sequences)\n",
        "        return texts\n",
        "\n",
        "    def pad_sequences(self, sequences):\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=self.max_sequence_length, padding='post', truncating='post')\n",
        "        return padded_sequences\n",
        "\n",
        "texts = [\n",
        "    \"This is a sentence.\",\n",
        "    \"Another sentence where.\",\n",
        "    \"And yet another one.\"\n",
        "]\n",
        "\n",
        "tokenizer = CustomTokenizer(max_words=20_000, max_sequence_length=MAX_SEQ_LENGTH)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = tokenizer.pad_sequences(sequences)\n",
        "texts_reconstructed = tokenizer.sequences_to_texts(sequences)\n",
        "\n",
        "print(\"Original texts:\", texts)\n",
        "print(\"Reconstructed texts:\", texts_reconstructed)\n",
        "print(\"Sequences:\", sequences)\n",
        "print(\"Padded sequences:\\n\", padded_sequences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vjqGuvcd2Dd",
        "outputId": "3a4927c8-a178-431d-aa95-bd6856eff4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original texts: ['This is a sentence.', 'Another sentence where.', 'And yet another one.']\n",
            "Reconstructed texts: ['this is a sentence', 'another sentence where', 'and yet another one']\n",
            "Sequences: [[8, 9, 10, 2], [3, 2, 11], [12, 13, 3, 14]]\n",
            "Padded sequences:\n",
            " [[ 8  9 10  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]\n",
            " [ 3  2 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]\n",
            " [12 13  3 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "MAX_SEQ_LENGTH = 50  # Maximum sequence length for padding\n",
        "\n",
        "class ChatbotTokenizer:\n",
        "    def __init__(self, model_name):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.max_seq_length = MAX_SEQ_LENGTH\n",
        "\n",
        "    def tokenize_sentences(self, sentences):\n",
        "        # Tokenize sentences and add special tokens for transformer models\n",
        "        tokenized = self.tokenizer(sentences, padding=True, truncation=True, max_length=self.max_seq_length, return_tensors='pt')\n",
        "        return tokenized\n",
        "\n",
        "    def detokenize(self, token_ids):\n",
        "        # Convert token IDs to text\n",
        "        text = self.tokenizer.decode(token_ids, skip_special_tokens=True)\n",
        "        return text\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return self.tokenizer.vocab_size\n",
        "\n",
        "# Example usage\n",
        "model_name = \"distilbert-base-uncased\"  # Change this to the desired transformer model\n",
        "sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"What is the weather today?\",\n",
        "    \"Tell me a joke!\",\n",
        "]\n",
        "\n",
        "tokenizer = ChatbotTokenizer(model_name)\n",
        "tokenized_sentences = tokenizer.tokenize_sentences(sentences)\n",
        "print(tokenized_sentences)\n",
        "\n",
        "# Accessing vocabulary size\n",
        "print(\"Vocabulary size:\", tokenizer.vocab_size)\n",
        "\n",
        "# Detokenize token IDs\n",
        "detokenized_text = tokenizer.detokenize(tokenized_sentences['input_ids'][0])\n",
        "print(\"Detokenized text:\", detokenized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "5f59b11e96d346bb91acd65ea97747cc",
            "a547a48b529d4837806b955d20838710",
            "7325c62c51214bc39f121ce57091f082",
            "740da8b3089d4326aedb172d7e559e0e",
            "9e31bf219fec46d0b8a39dd35ec83eb5",
            "74cf862300914af7ba1ecf6f7843441e",
            "1c2d4cd36e95405b89ae9d847bfa4a48",
            "8734987489b94c10a47fbd3c6cb31f73",
            "29cfc95fe8ca40d89d9f7ddb8ae8d649",
            "b4129021b17a402dae5b607037064441",
            "160165212ff24755a417caefbfc9b94a",
            "35ae40f7768e403f93b350c652980cd3",
            "b17fb5ff5e3649ac8dace4e1b5d77eee",
            "55fd18e5de1c4a6a8346cb3fe9edc57a",
            "98e4cb9419b24c2abdf6fb0742bcbc08",
            "707dd63b63644de18ed53f414c9e6c4e",
            "0cde2f0fe92a423ba26c8fe8e48efb5c",
            "2c29e711988c4e9fbac389bf11c68de9",
            "e268445352a94bd2a874ec5ed63c7e25",
            "7b995a62a2994dc6addb056fb55ceb0f",
            "32229aec92c54abebfd7b61f78afa917",
            "1ceea8bb68db499ca6d8ac347f6f094d",
            "8fbd4977a7ee45649ce98aa969c10888",
            "a620c693335448fab807fbf9a12aa717",
            "0308e7a96dd94739ae47f64ecf73f940",
            "e05e73e3f1ca456b8a66d88671220a82",
            "f65480219ee5489494ad93db84c26df7",
            "c8d8a125ad3f4a248820e324b8057baf",
            "17879a85342d4f60aba7fbd2ccdefe33",
            "13bd9bcb4e0a4ab1adc59b113a38556e",
            "93784ffcacf24d68902f3be138602caa",
            "565b2e8549884701b2a543924a484df2",
            "38471f64d57d4e0a9d2294c3b343ecd1",
            "5a4d49e4b7cf436b8c4f054cc1d01ecb",
            "b6d4e640f04f4327aa68c85a9bc1921e",
            "bd2b23bd9078403d827bb40c73f42adc",
            "93a874c6078b4c7fa97c0a941b25e185",
            "b3302ef5eaf447ceba5f88924ee0577b",
            "a87a7aad7b454da28e345ec31717c0f3",
            "399dae459d8c4270a909733300e2077b",
            "7851e89e1c9d49f8898a918495c6cfaf",
            "020916b186a545feb55f120ad8e4c8f6",
            "4034657f238c47f8a7fb89db84552df3",
            "e2825ac428f4494886393482b5645ca6"
          ]
        },
        "id": "rtA2TnALlwJv",
        "outputId": "335c4261-7ed9-4bc9-9b1f-dd063a747fb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f59b11e96d346bb91acd65ea97747cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35ae40f7768e403f93b350c652980cd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fbd4977a7ee45649ce98aa969c10888"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a4d49e4b7cf436b8c4f054cc1d01ecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 1029,  102],\n",
            "        [ 101, 2054, 2003, 1996, 4633, 2651, 1029,  102],\n",
            "        [ 101, 2425, 2033, 1037, 8257,  999,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 0]])}\n",
            "Vocabulary size: 30522\n",
            "Detokenized text: hello, how are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = self.positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def positional_encoding(self, length, depth):\n",
        "    depth = depth/2\n",
        "\n",
        "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "    angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "    pos_encoding = np.concatenate(\n",
        "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "        axis=-1)\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "2KXc4mQCX0az"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x\n",
        "\n",
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ],
      "metadata": {
        "id": "NeW2MvuBX_TY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ],
      "metadata": {
        "id": "bKAB4dGJYBOr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyper Params\n",
        "num_layers = 6\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "o1_3qKzkkFRw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ogJhZ24lmr0B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=tokenizer.vocab_size,\n",
        "    target_vocab_size=tokenizer.vocab_size,\n",
        "    dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "ouhEc61wkrHq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing for training"
      ],
      "metadata": {
        "id": "zeDYHnPzAbzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def prepare_batch(batch_df, tokenizer):\n",
        "    qs = batch_df['question'].tolist()\n",
        "    ans = batch_df['answer'].tolist()\n",
        "\n",
        "    qs_tokenized = tokenizer.tokenize_sentences(qs)\n",
        "    qs_input_ids = qs_tokenized['input_ids']\n",
        "    qs_attention_masks = qs_tokenized['attention_mask']\n",
        "\n",
        "    ans_tokenized = tokenizer.tokenize_sentences(ans)\n",
        "    ans_input_ids = ans_tokenized['input_ids']\n",
        "    ans_attention_masks = ans_tokenized['attention_mask']\n",
        "\n",
        "    return ((np.array(qs_input_ids), np.array(ans_input_ids)), np.array(ans_input_ids), np.array(ans_attention_masks))\n",
        "\n",
        "# Example usage\n",
        "train_batches = prepare_batch(train_ds, tokenizer)\n",
        "val_batches = prepare_batch(val_ds, tokenizer)\n",
        "\n",
        "\n",
        "def prepare_batch_test(batch_df, tokenizer):\n",
        "    qs = batch_df[0]\n",
        "    ans = batch_df[1]\n",
        "\n",
        "    qs_tokenized = tokenizer.tokenize_sentences(qs)\n",
        "    qs_input_ids = qs_tokenized['input_ids']\n",
        "    qs_attention_masks = qs_tokenized['attention_mask']\n",
        "\n",
        "    ans_tokenized = tokenizer.tokenize_sentences(ans)\n",
        "    ans_input_ids = ans_tokenized['input_ids']\n",
        "    ans_attention_masks = ans_tokenized['attention_mask']\n",
        "\n",
        "    return ((np.array(qs_input_ids), np.array(ans_input_ids)), np.array(ans_input_ids), np.array(ans_attention_masks))\n",
        "\n",
        "\n",
        "test_batches = prepare_batch_test(test_ds.iloc[1], tokenizer)\n"
      ],
      "metadata": {
        "id": "0uCbIMYGm2OT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT-F8b7doETE",
        "outputId": "d782eca0-1cf5-4501-8b35-f41aae5bfcc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[  101,  2129,  3060,  4841,  2020, 17352,  2000,  1996,  2149,\n",
              "            102]]),\n",
              "  array([[  101,  2004,  2107,  1010,  3060,  7489,  2024,  2000,  2022,\n",
              "           5182,  2013,  3060,  2137,  2111,  1010,  1996,  3732,  1997,\n",
              "           3183,  2024,  8481,  1997,  3262,  2225,  1998,  2430, 18076,\n",
              "           2040,  2020,  1999,  6767, 26896,  7559,  6588,  2716,  2000,\n",
              "           1996,  2142,  2163,  2011,  2965,  1997,  1996,  3181,  4448,\n",
              "           6658,  3119,  1012,   102]])),\n",
              " array([[  101,  2004,  2107,  1010,  3060,  7489,  2024,  2000,  2022,\n",
              "          5182,  2013,  3060,  2137,  2111,  1010,  1996,  3732,  1997,\n",
              "          3183,  2024,  8481,  1997,  3262,  2225,  1998,  2430, 18076,\n",
              "          2040,  2020,  1999,  6767, 26896,  7559,  6588,  2716,  2000,\n",
              "          1996,  2142,  2163,  2011,  2965,  1997,  1996,  3181,  4448,\n",
              "          6658,  3119,  1012,   102]]),\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "      'd_model': self.d_model,\n",
        "      'warmup_steps': self.warmup_steps,\n",
        "     }\n",
        "    return config\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "3mjKF8qXocLz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  matchs = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  matchs = matchs & mask\n",
        "\n",
        "  matchs = tf.cast(matchs, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(matchs)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "z8W4lRDBomcL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "y5LKsWM0opWs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "checkpoint_filepath = './tmp/checkpoint'\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
        "backup_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=\"./tmp/backup\")\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    include_optimizer=False,\n",
        "    filepath=checkpoint_filepath+\"/{epoch:02d}-{val_masked_accuracy:.2f}\",\n",
        "    monitor='val_masked_accuracy',\n",
        "    mode='max',\n",
        "    save_freq='epoch',\n",
        "    period=1,\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8DkdwnNoqw5",
        "outputId": "80ae8c61-5322-4eb7-bfc7-61088f9106f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(x=train_batches[0], y=train_batches[1],\n",
        "                epochs=40, validation_data=(val_batches), callbacks=[tensorboard_callback, backup_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm-PEbdrvdBP",
        "outputId": "abdad268-7c7a-43dc-ea77-57e6df95d26d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - ETA: 0s - loss: 10.3139 - masked_accuracy: 1.3475e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 49s 1s/step - loss: 10.3139 - masked_accuracy: 1.3475e-04 - val_loss: 6.8759 - val_masked_accuracy: 0.0129\n",
            "Epoch 2/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 10.1991 - masked_accuracy: 0.0622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 10.1991 - masked_accuracy: 0.0622 - val_loss: 6.7964 - val_masked_accuracy: 0.1147\n",
            "Epoch 3/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 10.0587 - masked_accuracy: 0.1328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 10.0587 - masked_accuracy: 0.1328 - val_loss: 6.6920 - val_masked_accuracy: 0.1732\n",
            "Epoch 4/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 9.8586 - masked_accuracy: 0.1807"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 9.8586 - masked_accuracy: 0.1807 - val_loss: 6.5493 - val_masked_accuracy: 0.1894\n",
            "Epoch 5/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 9.5993 - masked_accuracy: 0.2063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 43s 1s/step - loss: 9.5993 - masked_accuracy: 0.2063 - val_loss: 6.3822 - val_masked_accuracy: 0.2064\n",
            "Epoch 6/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 9.2994 - masked_accuracy: 0.2338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 9.2994 - masked_accuracy: 0.2338 - val_loss: 6.1965 - val_masked_accuracy: 0.2579\n",
            "Epoch 7/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 8.9695 - masked_accuracy: 0.2631"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 8.9695 - masked_accuracy: 0.2631 - val_loss: 5.9976 - val_masked_accuracy: 0.2753\n",
            "Epoch 8/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 8.6172 - masked_accuracy: 0.2840"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 8.6172 - masked_accuracy: 0.2840 - val_loss: 5.7905 - val_masked_accuracy: 0.2753\n",
            "Epoch 9/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 8.2552 - masked_accuracy: 0.2875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 8.2552 - masked_accuracy: 0.2875 - val_loss: 5.5790 - val_masked_accuracy: 0.2762\n",
            "Epoch 10/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 7.8905 - masked_accuracy: 0.2885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 7.8905 - masked_accuracy: 0.2885 - val_loss: 5.3718 - val_masked_accuracy: 0.2776\n",
            "Epoch 11/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 7.5345 - masked_accuracy: 0.2941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 7.5345 - masked_accuracy: 0.2941 - val_loss: 5.1718 - val_masked_accuracy: 0.2962\n",
            "Epoch 12/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 7.1964 - masked_accuracy: 0.3045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 43s 1s/step - loss: 7.1964 - masked_accuracy: 0.3045 - val_loss: 4.9773 - val_masked_accuracy: 0.3100\n",
            "Epoch 13/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 6.8727 - masked_accuracy: 0.3165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 43s 1s/step - loss: 6.8727 - masked_accuracy: 0.3165 - val_loss: 4.7607 - val_masked_accuracy: 0.3082\n",
            "Epoch 14/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 6.5367 - masked_accuracy: 0.3167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 6.5367 - masked_accuracy: 0.3167 - val_loss: 4.4967 - val_masked_accuracy: 0.3080\n",
            "Epoch 15/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 6.1833 - masked_accuracy: 0.3224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 6.1833 - masked_accuracy: 0.3224 - val_loss: 4.2588 - val_masked_accuracy: 0.3199\n",
            "Epoch 16/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 5.8291 - masked_accuracy: 0.3410"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 5.8291 - masked_accuracy: 0.3410 - val_loss: 4.0280 - val_masked_accuracy: 0.3576\n",
            "Epoch 17/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 5.4715 - masked_accuracy: 0.3780"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 5.4715 - masked_accuracy: 0.3780 - val_loss: 3.7954 - val_masked_accuracy: 0.3828\n",
            "Epoch 18/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 5.1154 - masked_accuracy: 0.4027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 5.1154 - masked_accuracy: 0.4027 - val_loss: 3.5640 - val_masked_accuracy: 0.4227\n",
            "Epoch 19/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 4.7630 - masked_accuracy: 0.4329"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 4.7630 - masked_accuracy: 0.4329 - val_loss: 3.3540 - val_masked_accuracy: 0.4327\n",
            "Epoch 20/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 4.4345 - masked_accuracy: 0.4476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 4.4345 - masked_accuracy: 0.4476 - val_loss: 3.1568 - val_masked_accuracy: 0.4506\n",
            "Epoch 21/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 4.1308 - masked_accuracy: 0.4617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 4.1308 - masked_accuracy: 0.4617 - val_loss: 2.9904 - val_masked_accuracy: 0.4673\n",
            "Epoch 22/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 3.8645 - masked_accuracy: 0.4761"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 3.8645 - masked_accuracy: 0.4761 - val_loss: 2.8499 - val_masked_accuracy: 0.4804\n",
            "Epoch 23/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 3.6257 - masked_accuracy: 0.4932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 3.6257 - masked_accuracy: 0.4932 - val_loss: 2.7148 - val_masked_accuracy: 0.5016\n",
            "Epoch 24/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 3.4061 - masked_accuracy: 0.5134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 3.4061 - masked_accuracy: 0.5134 - val_loss: 2.6024 - val_masked_accuracy: 0.5259\n",
            "Epoch 25/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 3.2047 - masked_accuracy: 0.5384"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 3.2047 - masked_accuracy: 0.5384 - val_loss: 2.4971 - val_masked_accuracy: 0.5524\n",
            "Epoch 26/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 3.0129 - masked_accuracy: 0.5652"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 3.0129 - masked_accuracy: 0.5652 - val_loss: 2.3955 - val_masked_accuracy: 0.5837\n",
            "Epoch 27/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.8257 - masked_accuracy: 0.5962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 2.8257 - masked_accuracy: 0.5962 - val_loss: 2.3072 - val_masked_accuracy: 0.6037\n",
            "Epoch 28/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.6472 - masked_accuracy: 0.6252"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 2.6472 - masked_accuracy: 0.6252 - val_loss: 2.2086 - val_masked_accuracy: 0.6305\n",
            "Epoch 29/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.4746 - masked_accuracy: 0.6559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 2.4746 - masked_accuracy: 0.6559 - val_loss: 2.1312 - val_masked_accuracy: 0.6551\n",
            "Epoch 30/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.3050 - masked_accuracy: 0.6876"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 2.3050 - masked_accuracy: 0.6876 - val_loss: 2.0473 - val_masked_accuracy: 0.6821\n",
            "Epoch 31/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.1416 - masked_accuracy: 0.7167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 2.1416 - masked_accuracy: 0.7167 - val_loss: 1.9640 - val_masked_accuracy: 0.7027\n",
            "Epoch 32/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.9898 - masked_accuracy: 0.7427"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 1.9898 - masked_accuracy: 0.7427 - val_loss: 1.8919 - val_masked_accuracy: 0.7271\n",
            "Epoch 33/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.8440 - masked_accuracy: 0.7702"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 1.8440 - masked_accuracy: 0.7702 - val_loss: 1.8325 - val_masked_accuracy: 0.7434\n",
            "Epoch 34/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.7006 - masked_accuracy: 0.7929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 1.7006 - masked_accuracy: 0.7929 - val_loss: 1.7685 - val_masked_accuracy: 0.7640\n",
            "Epoch 35/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.5676 - masked_accuracy: 0.8167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 1.5676 - masked_accuracy: 0.8167 - val_loss: 1.7145 - val_masked_accuracy: 0.7737\n",
            "Epoch 36/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.4368 - masked_accuracy: 0.8409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 1.4368 - masked_accuracy: 0.8409 - val_loss: 1.6593 - val_masked_accuracy: 0.7857\n",
            "Epoch 37/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.3142 - masked_accuracy: 0.8629"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 42s 1s/step - loss: 1.3142 - masked_accuracy: 0.8629 - val_loss: 1.6141 - val_masked_accuracy: 0.8023\n",
            "Epoch 38/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.1932 - masked_accuracy: 0.8817"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 44s 1s/step - loss: 1.1932 - masked_accuracy: 0.8817 - val_loss: 1.5556 - val_masked_accuracy: 0.8223\n",
            "Epoch 39/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.0835 - masked_accuracy: 0.8987"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 46s 1s/step - loss: 1.0835 - masked_accuracy: 0.8987 - val_loss: 1.5208 - val_masked_accuracy: 0.8367\n",
            "Epoch 40/40\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9775 - masked_accuracy: 0.9208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/33 [==============================] - 41s 1s/step - loss: 0.9775 - masked_accuracy: 0.9208 - val_loss: 1.4789 - val_masked_accuracy: 0.8520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79ad90178eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1"
      ],
      "metadata": {
        "id": "QoQ_8D9d_zBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform prediction\n",
        "predictions = transformer.predict(x=test_batches[0])\n",
        "\n",
        "# Apply argmax operation to get the indices of the maximum values\n",
        "predicted_ids = tf.argmax(predictions, axis=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQcQF6bVFRvt",
        "outputId": "4153f3e6-eee9-471a-86ab-fc4294e88f23"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 280ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf9ml_iG5tqE",
        "outputId": "23fe8355-0bd8-4eb2-c8ed-8e33181f8e62"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  101,  2129,  1037,  2300, 10216,  2573,   102]]),\n",
              " array([[  101, 15856,  5452,  2011,  2070,  7337,  1006,  4050, 28667,\n",
              "         11514,  3217, 18252,  2030, 16933,  1007,  1010,  1998, 16678,\n",
              "          2943,  2000,  4685,  6228,  2147,  2011,  3048,  1996,  8331,\n",
              "          1012,   102]]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the list of token IDs to a TensorFlow tensor\n",
        "predicted_token_ids_tensor = tf.constant(predicted_ids)\n",
        "\n",
        "# Convert the tensor to a ragged tensor\n",
        "predicted_token_ids_ragged = tf.RaggedTensor.from_tensor(predicted_token_ids_tensor)\n",
        "\n",
        "# Convert the ragged tensor to a list of lists\n",
        "predicted_token_ids_list = predicted_token_ids_ragged.to_list()\n",
        "\n",
        "# Process the token IDs to get the corresponding text\n",
        "predicted_text = \" \".join([tokenizer.detokenize(ids) for ids in predicted_token_ids_list])\n",
        "\n",
        "# Print the predicted text\n",
        "print(predicted_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhvIQAmLKOyf",
        "outputId": "2002b4ec-d9a3-411a-f9db-b38d54d3bf73"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "free operate by some value ( typically reciprocating or serving ), and race energy to perform mechanical work by el the fluid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.iloc[1][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ocqVHJZBz7hx",
        "outputId": "cda34e54-bc19-4451-eff7-b83e301bd2da"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pumps operate by some mechanism ( typically reciprocating or rotary ) , and consume energy to perform mechanical work by moving the fluid .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2"
      ],
      "metadata": {
        "id": "D40KDgif_U40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches_2 = prepare_batch_test(test_ds.iloc[2], tokenizer)\n",
        "\n",
        "# Perform prediction\n",
        "predictions = transformer.predict(x=test_batches_2[0])\n",
        "\n",
        "# Apply argmax operation to get the indices of the maximum values\n",
        "predicted_ids = tf.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r38x1JNk894M",
        "outputId": "04c88378-ce46-4946-aa79-a687b0d2a61a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 392ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the list of token IDs to a TensorFlow tensor\n",
        "predicted_token_ids_tensor = tf.constant(predicted_ids)\n",
        "\n",
        "# Convert the tensor to a ragged tensor\n",
        "predicted_token_ids_ragged = tf.RaggedTensor.from_tensor(predicted_token_ids_tensor)\n",
        "\n",
        "# Convert the ragged tensor to a list of lists\n",
        "predicted_token_ids_list = predicted_token_ids_ragged.to_list()\n",
        "\n",
        "# Process the token IDs to get the corresponding text\n",
        "predicted_text = \" \".join([tokenizer.detokenize(ids) for ids in predicted_token_ids_list])\n",
        "\n",
        "# Print the predicted text\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmHdjb0U-iTU",
        "outputId": "89c0e29a-77a0-4b4e-c927-72651182d013"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the actress who played loum, sue agency, was estate at the time of filming.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.iloc[2][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UdV1bKWA-nqN",
        "outputId": "19feaaf1-2939-4492-b43e-8e3a9ad63b14"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The actress who played Lolita , Sue Lyon , was fourteen at the time of filming .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3"
      ],
      "metadata": {
        "id": "zVDN5zm0_bHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches_3 = prepare_batch_test(test_ds.iloc[3], tokenizer)\n",
        "\n",
        "# Perform prediction\n",
        "predictions = transformer.predict(x=test_batches_3[0])\n",
        "\n",
        "# Apply argmax operation to get the indices of the maximum values\n",
        "predicted_ids = tf.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpN9E8Bo-rNg",
        "outputId": "653943e7-5235-4aca-f6c7-5afd74ae42ac"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 702ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the list of token IDs to a TensorFlow tensor\n",
        "predicted_token_ids_tensor = tf.constant(predicted_ids)\n",
        "\n",
        "# Convert the tensor to a ragged tensor\n",
        "predicted_token_ids_ragged = tf.RaggedTensor.from_tensor(predicted_token_ids_tensor)\n",
        "\n",
        "# Convert the ragged tensor to a list of lists\n",
        "predicted_token_ids_list = predicted_token_ids_ragged.to_list()\n",
        "\n",
        "# Process the token IDs to get the corresponding text\n",
        "predicted_text = \" \".join([tokenizer.detokenize(ids) for ids in predicted_token_ids_list])\n",
        "\n",
        "# Print the predicted text\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EPaziHm_kGm",
        "outputId": "87c46910-17d7-47b2-f133-2acd2713315e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "an dead ( georgia ), also known as an immunoglobulin ( ig ), is a large sum - shaped protein produced by b - cells that is used by the immune system to identify andallyize foreign objects such\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.iloc[3][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ndueDktp_mWp",
        "outputId": "7f87d083-902a-4059-ede0-e01c6e8876c9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'An antibody ( Ab ) , also known as an immunoglobulin ( Ig ) , is a large Y-shaped protein produced by B-cells that is used by the immune system to identify and neutralize foreign objects such as bacteria and viruses .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 4"
      ],
      "metadata": {
        "id": "rS4qixvS_3Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches_4 = prepare_batch_test(test_ds.iloc[4], tokenizer)\n",
        "\n",
        "# Perform prediction\n",
        "predictions = transformer.predict(x=test_batches_4[0])\n",
        "\n",
        "# Apply argmax operation to get the indices of the maximum values\n",
        "predicted_ids = tf.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMu6OcAZ_5k5",
        "outputId": "cb4ecdd8-a623-4730-e947-2d73d4b1c9f3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 733ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the list of token IDs to a TensorFlow tensor\n",
        "predicted_token_ids_tensor = tf.constant(predicted_ids)\n",
        "\n",
        "# Convert the tensor to a ragged tensor\n",
        "predicted_token_ids_ragged = tf.RaggedTensor.from_tensor(predicted_token_ids_tensor)\n",
        "\n",
        "# Convert the ragged tensor to a list of lists\n",
        "predicted_token_ids_list = predicted_token_ids_ragged.to_list()\n",
        "\n",
        "# Process the token IDs to get the corresponding text\n",
        "predicted_text = \" \".join([tokenizer.detokenize(ids) for ids in predicted_token_ids_list])\n",
        "\n",
        "# Print the predicted text\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWBObWdh_96_",
        "outputId": "38209564-e879-4d4c-c48e-2d4954b58f71"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the dead change a operations part of the foreign target, called an previously.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.iloc[4][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NnP04Kxc__pa",
        "outputId": "fae56750-6487-4e5f-eed8-2f5274f04857"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The antibody recognizes a unique part of the foreign target , called an antigen .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 5"
      ],
      "metadata": {
        "id": "mZukefvSAKO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches_5 = prepare_batch_test(test_ds.iloc[5], tokenizer)\n",
        "\n",
        "# Perform prediction\n",
        "predictions = transformer.predict(x=test_batches_5[0])\n",
        "\n",
        "# Apply argmax operation to get the indices of the maximum values\n",
        "predicted_ids = tf.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alQwcxR_AMKK",
        "outputId": "2a64e3aa-57a8-4671-8f5b-d7e79db2be1b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 433ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the list of token IDs to a TensorFlow tensor\n",
        "predicted_token_ids_tensor = tf.constant(predicted_ids)\n",
        "\n",
        "# Convert the tensor to a ragged tensor\n",
        "predicted_token_ids_ragged = tf.RaggedTensor.from_tensor(predicted_token_ids_tensor)\n",
        "\n",
        "# Convert the ragged tensor to a list of lists\n",
        "predicted_token_ids_list = predicted_token_ids_ragged.to_list()\n",
        "\n",
        "# Process the token IDs to get the corresponding text\n",
        "predicted_text = \" \".join([tokenizer.detokenize(ids) for ids in predicted_token_ids_list])\n",
        "\n",
        "# Print the predicted text\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVwakgV1AQOV",
        "outputId": "d7af76b6-3747-44a5-de74-39b27415b7ed"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "each tip of the ` ` grand'' of an gun contains a paratope ( a guitarist 1991 to a lock ) that is specific for one particular epitope ( mississippi characters to a key ) on an previously, types these two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.iloc[5][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0yXE54kuAR3r",
        "outputId": "011c5ee8-8a6e-4d6f-f62e-b6060de7cd3d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Each tip of the `` Y '' of an antibody contains a paratope ( a structure analogous to a lock ) that is specific for one particular epitope ( similarly analogous to a key ) on an antigen , allowing these two structures to bind together with precision .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VcdFndXAU4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 6"
      ],
      "metadata": {
        "id": "l_Ken9u8BA1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches_6 = prepare_batch_test(test_ds.iloc[6], tokenizer)\n",
        "\n",
        "# Perform prediction\n",
        "predictions = transformer.predict(x=test_batches_6[0])\n",
        "\n",
        "# Apply argmax operation to get the indices of the maximum values\n",
        "predicted_ids = tf.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WImZQUUtBCxN",
        "outputId": "b0fe58eb-a1c0-426c-c658-0e1abae20aea"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 781ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of token IDs to a TensorFlow tensor\n",
        "predicted_token_ids_tensor = tf.constant(predicted_ids)\n",
        "\n",
        "# Convert the tensor to a ragged tensor\n",
        "predicted_token_ids_ragged = tf.RaggedTensor.from_tensor(predicted_token_ids_tensor)\n",
        "\n",
        "# Convert the ragged tensor to a list of lists\n",
        "predicted_token_ids_list = predicted_token_ids_ragged.to_list()\n",
        "\n",
        "# Process the token IDs to get the corresponding text\n",
        "predicted_text = \" \".join([tokenizer.detokenize(ids) for ids in predicted_token_ids_list])\n",
        "\n",
        "# Print the predicted text\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zerusXWMBHdh",
        "outputId": "640670c8-4d49-42b4-fe23-4119808f53cb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using this binding value, an gun can work a microbe or an adverse cell for attack by other parts of the immune system, or can compoundsize its target directly ( for example, by plan a part of a microbe that isfi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.iloc[6][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OxRzDBDQBJYC",
        "outputId": "fae6a9a1-19b2-46a0-d204-e95303e8a82f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Using this binding mechanism , an antibody can tag a microbe or an infected cell for attack by other parts of the immune system , or can neutralize its target directly ( for example , by blocking a part of a microbe that is essential for its invasion and survival ) .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    }
  ]
}